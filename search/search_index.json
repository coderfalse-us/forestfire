{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"api_documentation/","title":"API Integration in ForestFire","text":""},{"location":"api_documentation/#introduction","title":"Introduction","text":"<p>This document provides a comprehensive overview of the API-related components used in the ForestFire project. The project integrates with external APIs to update pick sequences in the warehouse management system after optimization. This documentation covers the HTTP client, request/response models, authentication, error handling, and best practices.</p>"},{"location":"api_documentation/#api-components-overview","title":"API Components Overview","text":""},{"location":"api_documentation/#1-http-client-httpx","title":"1. HTTP Client: HTTPX","text":"<p>ForestFire uses HTTPX, a modern, fully featured HTTP client for Python that supports both synchronous and asynchronous APIs. HTTPX is used to make API calls to the warehouse management system.</p>"},{"location":"api_documentation/#key-features-of-httpx","title":"Key Features of HTTPX","text":"<ul> <li>Async Support: Native support for <code>async</code>/<code>await</code> syntax</li> <li>HTTP/2 Support: Modern HTTP protocol support</li> <li>Timeout Configuration: Configurable timeouts for requests</li> <li>SSL Verification: Options for SSL certificate verification</li> <li>Streaming Responses: Support for streaming responses</li> <li>Session Management: Client session management</li> </ul>"},{"location":"api_documentation/#usage-in-forestfire","title":"Usage in ForestFire","text":"<p>HTTPX is primarily used in the <code>BatchPickSequenceService</code> class to send optimized pick sequences to the external API:</p> <pre><code>async with httpx.AsyncClient(verify=False) as client:\n    response = await client.put(\n        self.api_url,\n        json=payload.model_dump(),\n        headers={\n            \"Authorization\": f\"Bearer {self.api_key}\",\n            \"Content-Type\": \"application/json\",\n            \"App-User-Id\": \"Forestfire\",\n            # Additional headers...\n        },\n        timeout=30.0,\n    )\n</code></pre>"},{"location":"api_documentation/#2-api-models-with-pydantic","title":"2. API Models with Pydantic","text":"<p>ForestFire uses Pydantic to define structured data models for API requests and responses. Pydantic provides data validation, serialization, and documentation capabilities.</p>"},{"location":"api_documentation/#key-api-models","title":"Key API Models","text":"<ol> <li> <p>PickSequenceUpdate</p> <ul> <li>Represents a single pick sequence update</li> <li>Contains information about picklist, batch, sequence, and identifiers</li> </ul> </li> <li> <p>PickTaskPayload</p> <ul> <li>Represents a pick task in the API payload</li> <li>Contains task ID, user assignment, batch, and picklists</li> </ul> </li> <li> <p>PickListPayload</p> <ul> <li>Represents a picklist in the API payload</li> <li>Contains picklist ID, sequence, and test information</li> </ul> </li> <li> <p>ApiPayload</p> <ul> <li>Top-level API payload model</li> <li>Contains account, business unit, warehouse, and pick tasks</li> </ul> </li> </ol>"},{"location":"api_documentation/#example-model-definition","title":"Example Model Definition","text":"<pre><code>class PickSequenceUpdate(BaseModel):\n    \"\"\"Model representing a pick sequence update\"\"\"\n\n    picklist_id: str = Field(..., description=\"Unique id for picklist\")\n    batch_id: str = Field(..., description=\"Batch identifier\")\n    pick_sequence: int = Field(\n        ..., ge=1, description=\"Sequence number for picking\"\n    )\n    picktask_id: str = Field(..., description=\"Pick task identifier\")\n    account_id: str = Field(..., description=\"Account identifier\")\n    business_unit_id: str = Field(..., description=\"Business unit identifier\")\n    warehouse_id: str = Field(..., description=\"Warehouse identifier\")\n\n    class Config:\n        frozen = True\n</code></pre>"},{"location":"api_documentation/#3-api-integration-service","title":"3. API Integration Service","text":"<p>The <code>BatchPickSequenceService</code> class serves as the main API integration service, responsible for:</p> <ol> <li>Transforming optimization results into API-compatible formats</li> <li>Constructing API payloads</li> <li>Sending requests to the external API</li> <li>Handling responses and errors</li> </ol>"},{"location":"api_documentation/#key-methods","title":"Key Methods","text":"<ul> <li><code>transform_updates_to_api_payload</code>: Transforms internal update models to API payload format</li> <li><code>send_sequence_update</code>: Sends the updates to the external API</li> <li><code>update_pick_sequences</code>: Orchestrates the entire process from optimization results to API updates</li> </ul>"},{"location":"api_documentation/#api-endpoint-details","title":"API Endpoint Details","text":""},{"location":"api_documentation/#batch-assign-api","title":"Batch Assign API","text":"<p>Endpoint: <code>https://picking-api.wms-core-pg.npaz.ohl.com/2025-18/api/picking/task/batchassign</code></p> <p>Method: PUT</p> <p>Purpose: Updates pick sequences for batches in the warehouse management system</p> <p>Authentication: Bearer token authentication</p> <p>Headers: - <code>Authorization</code>: Bearer token - <code>Content-Type</code>: application/json - <code>App-User-Id</code>: Application identifier - <code>App-Environment</code>: Environment identifier - <code>App-Account-id</code>: Account identifier - <code>App-BU-Id</code>: Business unit identifier - <code>App-WareHouse-Id</code>: Warehouse identifier</p> <p>Request Payload Structure:</p> <pre><code>{\n  \"AccountId\": \"ACC123\",\n  \"BusinessunitId\": \"BU123\",\n  \"WarehouseId\": \"WH123\",\n  \"PickTasks\": [\n    {\n      \"TaskId\": \"TASK123\",\n      \"UserAssigned\": \"BOB\",\n      \"Batch\": \"BATCH_0\",\n      \"AdditionalProperties\": {},\n      \"PickLists\": [\n        {\n          \"PickListId\": \"PL123\",\n          \"Sequence\": 1,\n          \"Test\": \"PF03\"\n        }\n      ]\n    }\n  ]\n}\n</code></pre>"},{"location":"api_documentation/#authentication-and-security","title":"Authentication and Security","text":""},{"location":"api_documentation/#api-key-management","title":"API Key Management","text":"<p>ForestFire uses a bearer token for API authentication:</p> <pre><code>self.api_key = \"1GkFdCZ6NzzbKsaTSsGY9GSFcuVZ2mrX7rnOKRQroHSQkoH0eMbU1UkkF1YtDartoVMwoVB4SyfunGCvJoaFzy7qRh_EqS_GoR39YFub\"\n</code></pre>"},{"location":"api_documentation/#ssl-verification","title":"SSL Verification","text":"<p>The current implementation disables SSL verification for development purposes:</p> <pre><code>async with httpx.AsyncClient(verify=False) as client:\n    # API request code\n</code></pre>"},{"location":"api_documentation/#error-handling","title":"Error Handling","text":"<p>ForestFire implements comprehensive error handling for API requests:</p> <pre><code>try:\n    response = await client.put(...)\n    response.raise_for_status()\n    logger.info(\"Successfully sent updates to Domain for account %s\", payload.AccountId)\nexcept httpx.RequestError as e:\n    logger.error(\"API request failed: %s\", e)\n    raise\nexcept httpx.HTTPStatusError as e:\n    logger.error(\n        \"API returned error status: %s, Response: %s\",\n        e,\n        e.response.text if hasattr(e, \"response\") else \"No response\",\n    )\n    raise\nexcept Exception as e:\n    logger.error(\"Error sending updates: %s\", e)\n    raise\n</code></pre>"},{"location":"api_documentation/#error-types-handled","title":"Error Types Handled","text":"<ol> <li>RequestError: Network-related errors (connection failures, timeouts)</li> <li>HTTPStatusError: HTTP status errors (4xx, 5xx responses)</li> <li>General Exceptions: Any other unexpected errors</li> </ol>"},{"location":"api_documentation/#logging-and-monitoring","title":"Logging and Monitoring","text":"<p>ForestFire implements detailed logging for API operations:</p> <pre><code>logger.info(\"Sending API request with payload: %s\", payload.model_dump())\nresponse = await client.put(...)\nlogger.info(\"API response status: %s\", response.status_code)\n</code></pre>"},{"location":"api_documentation/#testing-api-integration","title":"Testing API Integration","text":"<p>The ForestFire project includes tests for API integration using mocking:</p> <pre><code>@pytest.mark.asyncio\nasync def test_send_sequence_update(self):\n    # Arrange\n    service = BatchPickSequenceService()\n    updates = [MagicMock()]\n    mock_api_data = [{\"key\": \"value\"}]\n\n    # Mock the transform method\n    with patch.object(service, \"transform_updates_to_api_payload\") as mock_transform, \\\n         patch(\"httpx.AsyncClient.put\") as mock_put:\n        mock_transform.return_value = mock_api_data\n\n        # Mock the httpx response\n        mock_response = MagicMock()\n        mock_response.raise_for_status = MagicMock()\n        mock_put.return_value = mock_response\n\n        # Act\n        await service.send_sequence_update(updates)\n\n        # Assert\n        mock_transform.assert_called_once_with(updates)\n        mock_put.assert_called_once()\n</code></pre>"},{"location":"api_documentation/#future-improvements","title":"Future Improvements","text":"<ol> <li>API Key Management: Move API keys to environment variables or a secure vault</li> <li>Retry Mechanism: Implement exponential backoff for failed requests</li> <li>Circuit Breaker: Add circuit breaker pattern for API resilience</li> <li>API Versioning: Support multiple API versions</li> <li>Response Caching: Implement caching for appropriate endpoints</li> <li>Metrics Collection: Add metrics for API performance monitoring</li> </ol>"},{"location":"api_documentation/#conclusion","title":"Conclusion","text":"<p>The ForestFire project implements a robust API integration using modern Python libraries like HTTPX and Pydantic. The implementation follows good practices for error handling, logging, and data validation. Future improvements could focus on security, resilience, and performance optimization.</p> <p>By following the patterns and practices outlined in this documentation, developers can maintain and extend the API integration capabilities of the ForestFire project effectively.</p>"},{"location":"home/","title":"ForestFire - Warehouse Order Picking Optimization","text":""},{"location":"home/#overview","title":"Overview","text":"<p>ForestFire is a robust implementation of a warehouse order picking optimization system that efficiently addresses the Warehouse Picker Routing Problem. It uses a combination of Genetic Algorithms (GA) and Ant Colony Optimization (ACO) to assign items to pickers while ensuring optimized paths.</p> <p>The system minimizes total distance traveled by pickers in a warehouse by selecting the best assignments of items to pickers, incorporating picker capacities, and producing warehouse routes in a structured and logical manner. The codebase follows clean architecture principles with high test coverage (&gt;90%) and adheres to the Google style guide for Python.</p>"},{"location":"home/#objectives","title":"Objectives","text":"<ol> <li>Minimize Total Distance Traveled: Optimize picker paths to reduce cumulative picking distance and save time.</li> <li>Ensure Picker Capacity Constraints: Manage picker assignments, ensuring their capacity isn't exceeded.</li> <li>Route Optimization: Address the layout design of a warehouse with walkways and cross-segments.</li> <li>Simulate &amp; Visualize: Visualize picker assignments and paths for better insights.</li> </ol>"},{"location":"home/#features","title":"Features","text":"<ul> <li>Picker Assignment: Assigns items to warehouse pickers.</li> <li>Fitness Function: Evaluates picker assignments by computing total distances traveled, considering warehouse constraints.</li> <li>Path Optimization: Sorts picker paths to minimize unnecessary travel.</li> <li>Genetic Algorithm:</li> <li>Crossover and mutation operators to evolve solutions over iterations.</li> <li>Capacity-based picker constraints in mutation and crossover.</li> <li>Tournament selection for selecting parents.</li> <li>Ant Colony Optimization: Assigns items intelligently by considering heuristic and pheromone values.</li> <li>Database Querying: Extract warehouse data such as tasks, items, and staging areas from PostgreSQL tables.</li> <li>Visualization: Visualize picker paths and assignments in graphs using <code>matplotlib</code>.</li> </ul>"},{"location":"home/#installation","title":"Installation","text":"<ol> <li> <p>Clone the repository:    <code>bash    git clone https://github.com/forestfire.git    cd forestfire</code></p> </li> <li> <p>Install dependencies:    Install required Python libraries using pip:    <code>bash    pip install -r requirements.txt</code>    Required libraries:</p> </li> <li><code>numpy</code>: For efficient array operations and calculations</li> <li><code>matplotlib</code>: For visualizing picker assignments and routing paths</li> <li><code>psycopg2</code>: For PostgreSQL database connectivity</li> <li><code>pytest</code>: For running unit tests</li> <li> <p><code>pytest-cov</code>: For measuring test coverage</p> </li> <li> <p>Database configuration:    Update the PostgreSQL connection details in <code>forestfire/database/config.py</code>:    <code>python    DB_HOST = \"&lt;your-db-host&gt;\"    DB_NAME = \"&lt;your-db-name&gt;\"    DB_USER = \"&lt;your-db-user&gt;\"    DB_PASSWORD = \"&lt;your-db-password&gt;\"    DB_PORT = \"&lt;your-db-port&gt;\"</code></p> </li> <li> <p>Run tests:    <code>bash    python -m pytest</code></p> </li> </ol> <p>To check test coverage:    <code>bash    python -m pytest --cov=forestfire</code></p>"},{"location":"home/#how-it-works","title":"How It Works","text":"<ol> <li>Warehouse Data Inputs:</li> <li>Picker locations, item locations, and item picking tasks are fetched through <code>db_c()</code>.</li> <li> <p>Details are stored in the form of dictionaries/lists.</p> </li> <li> <p>Model Configuration:</p> </li> <li> <p>Parameters such as number of pickers, picker capacities, warehouse layout (walkways), and optimization algorithm hyperparameters are defined.</p> </li> <li> <p>Fitness Evaluation:</p> </li> <li>Calculates the Euclidean distances between picker locations and assigned items.</li> <li> <p>Ensures picker paths optimize their distance by following walkways/cross-segments.</p> </li> <li> <p>Optimization Process:</p> </li> <li>Initial Solution:<ul> <li>Random initial population of picker-to-item assignments.</li> <li>Evaluate each solution's fitness by calculating total traveled distances.</li> </ul> </li> <li>Ant Colony Optimization:<ul> <li>Compute heuristic (inverse distance) and pheromone values for each item.</li> <li>Build an initial solution guided by these parameters.</li> </ul> </li> <li>Genetic Algorithm:<ul> <li>Evolve the solution over a number of iterations:</li> <li>Tournament Selection: Select top individuals from the population.</li> <li>Crossover: Combine parent solutions (single-point &amp; uniform).</li> <li>Mutation: Alter solutions to maintain diversity while enforcing capacity constraints.</li> </ul> </li> <li>Best Solution: Retrieve and plot the best picker assignments.</li> </ol>"},{"location":"home/#project-structure","title":"Project Structure","text":""},{"location":"home/#key-directories","title":"Key Directories","text":"<ol> <li> <p><code>forestfire/</code>:    Main package containing all modules.</p> </li> <li> <p><code>algorithms/</code>: Implementation of optimization algorithms</p> <ul> <li><code>ant_colony.py</code>: Ant Colony Optimization algorithm</li> <li><code>genetic.py</code>: Genetic Algorithm implementation</li> </ul> </li> <li> <p><code>database/</code>: Database connectivity and repository pattern</p> <ul> <li><code>config.py</code>: Database configuration</li> <li><code>connection.py</code>: Database connection management</li> <li><code>repository.py</code>: Base repository class</li> <li><code>services/</code>: Service layer for database operations</li> <li><code>picklist.py</code>: Repository for picklist data</li> <li><code>batch_pick_seq_service.py</code>: Service for batch pick sequences</li> </ul> </li> <li> <p><code>optimizer/</code>: Core optimization logic</p> <ul> <li><code>models/</code>: Data models</li> <li><code>route.py</code>: Route representation</li> <li><code>services/</code>: Optimization services</li> <li><code>routing.py</code>: Route optimization logic</li> <li><code>distance.py</code>: Distance calculation utilities</li> </ul> </li> <li> <p><code>plots/</code>: Visualization utilities</p> <ul> <li><code>graph.py</code>: Path visualization</li> </ul> </li> <li> <p><code>utils/</code>: Utility functions and configuration</p> <ul> <li><code>config.py</code>: Global configuration parameters</li> </ul> </li> <li> <p><code>tests/</code>:    Comprehensive test suite with &gt;90% coverage.</p> </li> <li> <p><code>main.py</code>:    Entry point that orchestrates the optimization process.</p> </li> <li> <p><code>requirements.txt</code>:    List of dependencies used in the project.</p> </li> <li> <p><code>README.md</code>:    Documentation (this file).</p> </li> </ol>"},{"location":"home/#key-classes-and-functions","title":"Key Classes and Functions","text":"<ol> <li> <p><code>AntColonyOptimizer</code>:    Implements ant colony optimization for item-to-picker assignment.</p> </li> <li> <p><code>GeneticOperator</code>:    Provides genetic algorithm operations like crossover and mutation.</p> </li> <li> <p><code>RouteOptimizer</code>:    Calculates optimal routes for pickers based on assigned items.</p> </li> <li> <p><code>PicklistRepository</code>:    Fetches and processes picklist data from the database.</p> </li> <li> <p><code>PathVisualizer</code>:    Visualizes picker routes and assignments.</p> </li> </ol>"},{"location":"home/#usage","title":"Usage","text":"<ol> <li> <p>Run the Optimization:    Execute the main script via terminal:    <code>bash    python main.py</code></p> </li> <li> <p>View Outputs:</p> </li> <li>Picker assignments for items</li> <li>Total distance traveled after optimization</li> <li> <p>Visual plots of picker paths in the <code>output</code> directory</p> </li> <li> <p>Modify Parameters:    Customize parameters in <code>forestfire/utils/config.py</code>:</p> </li> <li><code>NUM_PICKERS</code>: Number of pickers in the warehouse</li> <li><code>PICKER_CAPACITIES</code>: Capacity constraints for each picker</li> <li><code>MAX_ITERATIONS</code>: Maximum number of iterations for optimization</li> <li><code>POPULATION_SIZE</code>: Size of the population for genetic algorithm</li> <li><code>CROSSOVER_RATE</code>: Probability of crossover in genetic algorithm</li> <li><code>MUTATION_RATE</code>: Probability of mutation in genetic algorithm</li> <li><code>NUM_ANTS</code>: Number of ants in ACO algorithm</li> <li><code>ALPHA</code>: Pheromone importance factor in ACO</li> <li><code>BETA</code>: Heuristic importance factor in ACO</li> <li><code>RHO</code>: Pheromone evaporation rate in ACO</li> </ol>"},{"location":"home/#key-parameters-customizations","title":"Key Parameters &amp; Customizations","text":"Parameter Description Default Value <code>num_pickers</code> Total number of pickers in the warehouse. <code>10</code> <code>picker_capacities</code> A list of picker capacities (number of items each picker can handle). <code>[10, 10, ..., 10]</code> <code>num_items</code> Total number of items to be picked. <code>100</code> <code>MaxIt</code> Maximum number of iterations for the genetic algorithm. <code>50</code> <code>nPop</code> Population size for the genetic algorithm. <code>150</code> <code>pc (probability crossover)</code> Crossover rate for genetic algorithm. <code>0.90</code> <code>pm (probability mutation)</code> Mutation rate for genetic algorithm. <code>0.04</code> <code>num_ants</code> Number of ants in the ant colony optimization algorithm. <code>25</code> <code>rho</code> Pheromone evaporation rate (used in ACO). <code>0.5</code> <code>alpha</code> Influence of pheromone trails in ACO. <code>1.0</code> <code>beta</code> Influence of heuristic information (1/distance) in ACO. <code>2.0</code> <code>start_row</code> Starting row position in the warehouse layout for items/lines. <code>0</code> <code>step_between_rows</code> Distance between rows in warehouse layout. <code>10</code> <code>picker_locations</code> List of fixed picker start locations (x, y). Predefined Coordinates"},{"location":"home/#visualization","title":"Visualization","text":"<ul> <li>Each picker is assigned items and a route for optimization.</li> <li>Visualizations include:</li> <li>Picker start locations (blue markers).</li> <li>All item locations (red markers).</li> <li>Picker travel path (brown lines connecting items).</li> </ul>"},{"location":"home/#recent-improvements","title":"Recent Improvements","text":"<ol> <li>Code Architecture: Refactored to follow clean architecture principles with proper separation of concerns.</li> <li>Test Coverage: Achieved &gt;90% test coverage with comprehensive unit tests.</li> <li>Code Quality: Implemented Google style guide for consistent code formatting.</li> <li>Database Access: Implemented repository pattern with read-only database sessions to prevent accidental data insertion.</li> </ol>"},{"location":"home/#future-work","title":"Future Work","text":"<ol> <li>Dynamic Layout Adaptability: Extend the system to adapt to different warehouse layouts (e.g., uneven rows, zones).</li> <li>Multi-Objective Optimization: Incorporate additional objectives such as picker workload balancing or time-based constraints.</li> <li>Real-Time Integration: Connect to warehouse systems for real-time item locations and route updates.</li> <li>Improved Crossover &amp; Mutation: Implement more sophisticated crossovers and adaptive mutation rates.</li> <li>Performance Optimization: Enhance algorithm performance for larger warehouses and more complex scenarios.</li> </ol>"},{"location":"home/#contact-support","title":"Contact &amp; Support","text":"<p>For any questions or support, please reach out to: - GitHub Issues: Submit an Issue</p>"},{"location":"home/#contributing","title":"Contributing","text":"<p>Contributions are welcome! Please feel free to submit a Pull Request.</p> <ol> <li>Fork the repository</li> <li>Create your feature branch (<code>git checkout -b feature/amazing-feature</code>)</li> <li>Make your changes and ensure tests pass (<code>python -m pytest</code>)</li> <li>Commit your changes (<code>git commit -m 'Add some amazing feature'</code>)</li> <li>Push to the branch (<code>git push origin feature/amazing-feature</code>)</li> <li>Open a Pull Request</li> </ol> <p>Happy Optimizing! \ud83d\ude80\ud83d\udea2</p>"},{"location":"mkdocs/","title":"Welcome to MkDocs","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"mkdocs/#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"mkdocs/#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"orm_guide/","title":"Object-Relational Mapping (ORM): A Comprehensive Guide","text":""},{"location":"orm_guide/#introduction","title":"Introduction","text":"<p>Object-Relational Mapping (ORM) is a programming technique that converts data between incompatible type systems in object-oriented programming languages and relational databases. ORM tools create a \"virtual object database\" that can be used from within the programming language, eliminating the need to write SQL queries directly.</p> <p>This document provides an overview of ORM concepts, benefits, challenges, and a comparison of popular Python ORM tools, with recommendations for the best options based on different project requirements.</p>"},{"location":"orm_guide/#understanding-orm","title":"Understanding ORM","text":""},{"location":"orm_guide/#what-is-orm","title":"What is ORM?","text":"<p>ORM acts as a bridge between relational databases and object-oriented programming languages. It maps:</p> <ul> <li>Database tables to classes</li> <li>Table rows to objects</li> <li>Columns to object attributes</li> <li>Relationships to object references</li> </ul>"},{"location":"orm_guide/#current-implementation-in-forestfire","title":"Current Implementation in ForestFire","text":"<p>Currently, the ForestFire project uses direct database access with psycopg2 for PostgreSQL, implementing a repository pattern with classes like:</p> <ul> <li><code>BaseRepository</code>: Provides common database operations</li> <li><code>PicklistRepository</code>: Handles picklist-specific database operations</li> <li><code>BatchPickSequenceService</code>: Manages pick sequence updates</li> </ul> <p>While this approach works well, implementing an ORM could provide additional benefits in terms of code maintainability and development speed.</p>"},{"location":"orm_guide/#benefits-of-using-orm","title":"Benefits of Using ORM","text":""},{"location":"orm_guide/#1-productivity-and-development-speed","title":"1. Productivity and Development Speed","text":"<ul> <li>Reduced Boilerplate: Less code to write for database operations</li> <li>Rapid Development: Faster implementation of data models and operations</li> <li>Focus on Business Logic: Spend less time writing SQL and more time on application logic</li> </ul>"},{"location":"orm_guide/#2-code-quality-and-maintainability","title":"2. Code Quality and Maintainability","text":"<ul> <li>DRY Principle: Define data models in one place</li> <li>Consistent Patterns: Standardized approach to database operations</li> <li>Type Safety: Catch errors at compile/runtime rather than during database operations</li> <li>Code Organization: Clear separation between data models and business logic</li> </ul>"},{"location":"orm_guide/#3-database-abstraction","title":"3. Database Abstraction","text":"<ul> <li>Database Agnostic: Switch database backends with minimal code changes</li> <li>Migration Support: Tools for evolving database schema over time</li> <li>Dialect Handling: Automatically handles differences in SQL dialects</li> </ul>"},{"location":"orm_guide/#4-security","title":"4. Security","text":"<ul> <li>SQL Injection Prevention: Parameterized queries by default</li> <li>Input Validation: Built-in validation for data types and constraints</li> <li>Access Control: Centralized control over database operations</li> </ul>"},{"location":"orm_guide/#5-performance-optimization","title":"5. Performance Optimization","text":"<ul> <li>Lazy Loading: Load related data only when needed</li> <li>Eager Loading: Optimize by loading related data in a single query</li> <li>Connection Pooling: Efficient management of database connections</li> <li>Query Optimization: Intelligent query generation and caching</li> </ul>"},{"location":"orm_guide/#challenges-and-considerations","title":"Challenges and Considerations","text":""},{"location":"orm_guide/#1-performance-overhead","title":"1. Performance Overhead","text":"<ul> <li>Additional abstraction layer can introduce performance costs</li> <li>Complex queries may be less efficient than hand-optimized SQL</li> <li>Learning when to use raw SQL vs. ORM queries is important</li> </ul>"},{"location":"orm_guide/#2-learning-curve","title":"2. Learning Curve","text":"<ul> <li>Understanding ORM concepts and specific tool implementations</li> <li>Debugging can be more complex when issues occur in the ORM layer</li> <li>May require team training for effective use</li> </ul>"},{"location":"orm_guide/#3-limited-control","title":"3. Limited Control","text":"<ul> <li>Some complex database features may not be fully supported</li> <li>Custom SQL may still be needed for highly optimized operations</li> <li>Database-specific optimizations might be lost</li> </ul>"},{"location":"orm_guide/#4-complexity-in-large-projects","title":"4. Complexity in Large Projects","text":"<ul> <li>Can lead to complex object graphs and relationship management</li> <li>May introduce \"impedance mismatch\" between object and relational models</li> <li>Performance tuning becomes more challenging</li> </ul>"},{"location":"orm_guide/#popular-python-orm-tools","title":"Popular Python ORM Tools","text":""},{"location":"orm_guide/#1-sqlalchemy","title":"1. SQLAlchemy","text":"<p>SQLAlchemy is the most powerful and flexible ORM for Python, offering both high-level ORM and low-level SQL expression language.</p>"},{"location":"orm_guide/#key-features","title":"Key Features:","text":"<ul> <li>Comprehensive: Full-featured ORM with transaction support</li> <li>Flexible: Works at multiple levels of abstraction</li> <li>Powerful: Supports complex queries and relationships</li> <li>Database Agnostic: Works with PostgreSQL, MySQL, SQLite, Oracle, MS SQL, and more</li> <li>Mature: Well-established with extensive documentation</li> <li>Active Community: Regular updates and broad adoption</li> </ul>"},{"location":"orm_guide/#best-for","title":"Best For:","text":"<ul> <li>Complex enterprise applications</li> <li>Projects requiring fine-grained control</li> <li>Applications that might need to switch between databases</li> <li>Systems with complex data models and relationships</li> </ul>"},{"location":"orm_guide/#example","title":"Example:","text":"<pre><code>from sqlalchemy import create_engine, Column, Integer, String, ForeignKey\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import relationship, sessionmaker\n\nBase = declarative_base()\n\nclass Picker(Base):\n    __tablename__ = 'pickers'\n\n    id = Column(Integer, primary_key=True)\n    name = Column(String)\n    location_x = Column(Integer)\n    location_y = Column(Integer)\n    capacity = Column(Integer)\n\n    routes = relationship(\"Route\", back_populates=\"picker\")\n\nclass Route(Base):\n    __tablename__ = 'routes'\n\n    id = Column(Integer, primary_key=True)\n    picker_id = Column(Integer, ForeignKey('pickers.id'))\n    cost = Column(Float)\n\n    picker = relationship(\"Picker\", back_populates=\"routes\")\n    locations = relationship(\"RouteLocation\")\n\n# Create engine and session\nengine = create_engine('postgresql://user:password@localhost/forestfire')\nBase.metadata.create_all(engine)\nSession = sessionmaker(bind=engine)\nsession = Session()\n\n# Query example\npickers = session.query(Picker).filter(Picker.capacity &gt; 5).all()\n</code></pre>"},{"location":"orm_guide/#2-django-orm","title":"2. Django ORM","text":"<p>Django ORM is part of the Django web framework but can be used independently. It's designed for rapid development and simplicity.</p>"},{"location":"orm_guide/#key-features_1","title":"Key Features:","text":"<ul> <li>Integrated: Seamlessly works with Django framework</li> <li>Simple API: Easy to learn and use</li> <li>Admin Interface: Automatic admin UI generation</li> <li>Migrations: Built-in schema migration system</li> <li>Validation: Integrated with Django's form validation</li> </ul>"},{"location":"orm_guide/#best-for_1","title":"Best For:","text":"<ul> <li>Web applications using Django</li> <li>Projects prioritizing development speed</li> <li>Applications with straightforward data models</li> <li>Teams already familiar with Django</li> </ul>"},{"location":"orm_guide/#example_1","title":"Example:","text":"<pre><code>from django.db import models\n\nclass Picker(models.Model):\n    name = models.CharField(max_length=100)\n    location_x = models.IntegerField()\n    location_y = models.IntegerField()\n    capacity = models.IntegerField()\n\n    def __str__(self):\n        return self.name\n\nclass Route(models.Model):\n    picker = models.ForeignKey(Picker, on_delete=models.CASCADE, related_name='routes')\n    cost = models.FloatField()\n\n    def __str__(self):\n        return f\"Route for {self.picker.name}\"\n\n# Query example\npickers = Picker.objects.filter(capacity__gt=5)\n</code></pre>"},{"location":"orm_guide/#3-peewee","title":"3. Peewee","text":"<p>Peewee is a small, expressive ORM that supports PostgreSQL, MySQL, and SQLite.</p>"},{"location":"orm_guide/#key-features_2","title":"Key Features:","text":"<ul> <li>Lightweight: Small codebase with minimal dependencies</li> <li>Simple: Easy to learn and use</li> <li>Expressive: Intuitive query syntax</li> <li>Extensible: Easy to extend with custom fields and behaviors</li> </ul>"},{"location":"orm_guide/#best-for_2","title":"Best For:","text":"<ul> <li>Small to medium-sized applications</li> <li>Projects where simplicity is a priority</li> <li>Applications with straightforward data models</li> <li>Learning ORM concepts</li> </ul>"},{"location":"orm_guide/#example_2","title":"Example:","text":"<pre><code>from peewee import *\n\ndb = PostgresqlDatabase('forestfire', user='user', password='password')\n\nclass BaseModel(Model):\n    class Meta:\n        database = db\n\nclass Picker(BaseModel):\n    name = CharField()\n    location_x = IntegerField()\n    location_y = IntegerField()\n    capacity = IntegerField()\n\nclass Route(BaseModel):\n    picker = ForeignKeyField(Picker, backref='routes')\n    cost = FloatField()\n\n# Create tables\ndb.create_tables([Picker, Route])\n\n# Query example\npickers = Picker.select().where(Picker.capacity &gt; 5)\n</code></pre>"},{"location":"orm_guide/#4-tortoise-orm","title":"4. Tortoise ORM","text":"<p>Tortoise ORM is an async ORM inspired by Django ORM for Python asyncio.</p>"},{"location":"orm_guide/#key-features_3","title":"Key Features:","text":"<ul> <li>Async/Await: Built for asyncio from the ground up</li> <li>Django-like: Familiar API for Django users</li> <li>Type Hints: Strong typing support</li> <li>Multiple Databases: Supports PostgreSQL, MySQL, SQLite, and more</li> </ul>"},{"location":"orm_guide/#best-for_3","title":"Best For:","text":"<ul> <li>Async applications</li> <li>Projects using FastAPI or other async frameworks</li> <li>Applications requiring high concurrency</li> <li>Teams familiar with Django ORM</li> </ul>"},{"location":"orm_guide/#example_3","title":"Example:","text":"<pre><code>from tortoise import Model, fields\nfrom tortoise.contrib.pydantic import pydantic_model_creator\n\nclass Picker(Model):\n    id = fields.IntField(pk=True)\n    name = fields.CharField(max_length=100)\n    location_x = fields.IntField()\n    location_y = fields.IntField()\n    capacity = fields.IntField()\n\nclass Route(Model):\n    id = fields.IntField(pk=True)\n    picker = fields.ForeignKeyField('models.Picker', related_name='routes')\n    cost = fields.FloatField()\n\n# Generate Pydantic models\nPickerPydantic = pydantic_model_creator(Picker)\n\n# Query example (async)\nasync def get_pickers():\n    return await Picker.filter(capacity__gt=5)\n</code></pre>"},{"location":"orm_guide/#5-sqlmodel","title":"5. SQLModel","text":"<p>SQLModel is a library for interacting with SQL databases from Python code, with Python objects. It's based on Pydantic and SQLAlchemy.</p>"},{"location":"orm_guide/#key-features_4","title":"Key Features:","text":"<ul> <li>Pydantic Integration: Uses Pydantic for data validation</li> <li>SQLAlchemy Core: Built on top of SQLAlchemy</li> <li>Type Annotations: Strong typing support</li> <li>FastAPI Compatible: Works seamlessly with FastAPI</li> </ul>"},{"location":"orm_guide/#best-for_4","title":"Best For:","text":"<ul> <li>Projects using FastAPI</li> <li>Applications already using Pydantic</li> <li>Teams wanting SQLAlchemy power with simpler syntax</li> <li>Modern Python applications using type hints</li> </ul>"},{"location":"orm_guide/#example_4","title":"Example:","text":"<pre><code>from typing import Optional, List\nfrom sqlmodel import Field, Session, SQLModel, create_engine, Relationship\n\nclass Picker(SQLModel, table=True):\n    id: Optional[int] = Field(default=None, primary_key=True)\n    name: str\n    location_x: int\n    location_y: int\n    capacity: int\n\n    routes: List[\"Route\"] = Relationship(back_populates=\"picker\")\n\nclass Route(SQLModel, table=True):\n    id: Optional[int] = Field(default=None, primary_key=True)\n    picker_id: int = Field(foreign_key=\"picker.id\")\n    cost: float\n\n    picker: Picker = Relationship(back_populates=\"routes\")\n\n# Create engine\nengine = create_engine(\"postgresql://user:password@localhost/forestfire\")\nSQLModel.metadata.create_all(engine)\n\n# Query example\nwith Session(engine) as session:\n    pickers = session.query(Picker).filter(Picker.capacity &gt; 5).all()\n</code></pre>"},{"location":"orm_guide/#recommendation-sqlalchemy","title":"Recommendation: SQLAlchemy","text":"<p>For the ForestFire project, SQLAlchemy would be the recommended ORM solution for the following reasons:</p> <ol> <li>Flexibility: Provides both high-level ORM and low-level SQL expression language, allowing gradual migration from raw SQL</li> <li>PostgreSQL Support: Excellent support for PostgreSQL, which is currently used in the project</li> <li>Repository Pattern Compatibility: Can be integrated with the existing repository pattern</li> <li>Performance: Offers fine-grained control over query optimization</li> <li>Mature Ecosystem: Well-established with extensive documentation and community support</li> <li>Migration Path: Allows for incremental adoption alongside existing code</li> </ol>"},{"location":"orm_guide/#implementation-strategy","title":"Implementation Strategy","text":"<p>If you decide to adopt SQLAlchemy in the ForestFire project, consider the following implementation strategy:</p> <ol> <li>Start Small: Begin by implementing ORM models for a single domain entity</li> <li>Incremental Migration: Gradually replace direct SQL queries with ORM equivalents</li> <li>Repository Adaptation: Adapt existing repositories to use SQLAlchemy sessions</li> <li>Maintain Abstraction: Keep the repository pattern as an abstraction over the ORM</li> <li>Performance Testing: Compare performance between ORM and direct SQL approaches</li> </ol>"},{"location":"orm_guide/#conclusion","title":"Conclusion","text":"<p>ORM tools provide significant benefits for database interaction in Python applications, including improved productivity, code quality, and maintainability. While there are challenges to consider, the right ORM tool can greatly enhance your development experience and application architecture.</p> <p>For the ForestFire project, SQLAlchemy offers the best combination of power, flexibility, and compatibility with the existing codebase. However, the choice of ORM should ultimately be based on your specific project requirements, team expertise, and performance considerations.</p>"},{"location":"package_managers/","title":"Python Package Managers: A Comprehensive Guide","text":""},{"location":"package_managers/#introduction","title":"Introduction","text":"<p>Package managers are essential tools in modern software development that automate the process of installing, upgrading, configuring, and removing software packages in a consistent manner. They help developers manage dependencies, ensure compatibility between different libraries, and maintain reproducible development environments.</p> <p>This document provides an overview of popular Python package managers, with a special focus on <code>uv</code>, which is the package manager used in the ForestFire project.</p>"},{"location":"package_managers/#common-python-package-managers","title":"Common Python Package Managers","text":""},{"location":"package_managers/#1-pip","title":"1. pip","text":"<p>pip is the default package installer for Python and the most widely used package manager in the Python ecosystem.</p> <p>Key Features: - Simple command-line interface - Access to Python Package Index (PyPI) - Support for requirements files - Ability to install from version control systems - Virtual environment integration</p> <p>Limitations: - Lacks dependency resolution capabilities - No built-in environment management - Can lead to dependency conflicts</p>"},{"location":"package_managers/#2-conda","title":"2. conda","text":"<p>conda is a cross-platform package manager that can install packages from both the Anaconda repository and PyPI.</p> <p>Key Features: - Cross-platform package management - Environment management - Handles non-Python dependencies - Better dependency resolution than pip - Support for multiple programming languages</p> <p>Limitations: - Slower than pip for Python-only dependencies - Larger footprint - Different package ecosystem than PyPI</p>"},{"location":"package_managers/#3-poetry","title":"3. Poetry","text":"<p>Poetry is a modern dependency management and packaging tool for Python.</p> <p>Key Features: - Dependency resolution - Virtual environment management - Build and publishing capabilities - Lock file for reproducible installations - Intuitive command-line interface</p> <p>Limitations: - Steeper learning curve than pip - Not as widely adopted as pip - Occasional compatibility issues with some packages</p>"},{"location":"package_managers/#4-pipenv","title":"4. Pipenv","text":"<p>Pipenv combines pip and virtualenv into a single tool.</p> <p>Key Features: - Automatic virtual environment management - Generates Pipfile and Pipfile.lock - Security features - Dependency resolution</p> <p>Limitations: - Slower than pip - Development has been inconsistent - Complex dependency resolution can be slow</p>"},{"location":"package_managers/#uv-the-modern-python-package-manager","title":"uv: The Modern Python Package Manager","text":""},{"location":"package_managers/#overview","title":"Overview","text":"<p>uv is a modern, high-performance Python package manager and resolver written in Rust. It's designed to be a drop-in replacement for pip, pip-tools, and virtualenv, offering significant performance improvements and enhanced features.</p>"},{"location":"package_managers/#key-features-of-uv","title":"Key Features of uv","text":""},{"location":"package_managers/#1-exceptional-performance","title":"1. Exceptional Performance","text":"<ul> <li>Blazing Fast: uv is significantly faster than traditional Python package managers, with installation speeds up to 10-100x faster than pip.</li> <li>Parallel Downloads: Downloads and installs packages in parallel.</li> <li>Rust Implementation: Built with Rust for memory safety and performance.</li> </ul>"},{"location":"package_managers/#2-compatibility","title":"2. Compatibility","text":"<ul> <li>Drop-in Replacement: Works as a replacement for pip, pip-tools, and virtualenv.</li> <li>Standard Format Support: Compatible with requirements.txt, pyproject.toml, and other standard Python packaging formats.</li> <li>Lock File: Uses a lock file (uv.lock) to ensure reproducible installations.</li> </ul>"},{"location":"package_managers/#3-advanced-dependency-resolution","title":"3. Advanced Dependency Resolution","text":"<ul> <li>Fast Resolver: Efficiently resolves dependencies without conflicts.</li> <li>Deterministic Builds: Ensures consistent installations across different environments.</li> <li>PEP 517/518 Support: Full support for modern Python packaging standards.</li> </ul>"},{"location":"package_managers/#4-virtual-environment-management","title":"4. Virtual Environment Management","text":"<ul> <li>Integrated venv Creation: Can create and manage virtual environments.</li> <li>Seamless Integration: Works with existing virtual environments.</li> </ul>"},{"location":"package_managers/#using-uv-in-the-forestfire-project","title":"Using uv in the ForestFire Project","text":"<p>Our project leverages uv for dependency management with the following configuration:</p> <ol> <li>Dependencies defined in pyproject.toml:    ```toml    [project]    name = \"forestfire\"    version = \"0.1.0\"    description = \"Add your description here\"    readme = \"README.md\"    requires-python = \"&gt;=3.12\"    dependencies = [        \"dotenv&gt;=0.9.9\",        \"httpx&gt;=0.28.1\",        \"matplotlib&gt;=3.10.1\",        \"numpy&gt;=2.2.5\",        \"pre-commit&gt;=4.2.0\",        \"psycopg2&gt;=2.9.10\",        \"pydantic&gt;=2.11.4\",    ]</li> </ol> <p>[dependency-groups]    dev = [        \"ruff&gt;=0.11.8\",    ]    ```</p> <ol> <li>Lock file (uv.lock) ensures reproducible builds across different environments.</li> </ol>"},{"location":"package_managers/#benefits-of-using-uv-in-our-project","title":"Benefits of Using uv in Our Project","text":"<ol> <li>Development Speed: Faster dependency installation means less time waiting and more time coding.</li> <li>Reliability: Deterministic builds ensure consistent behavior across development, testing, and production environments.</li> <li>Modern Tooling: Support for the latest Python packaging standards.</li> <li>Simplified Workflow: Single tool for virtual environment management and package installation.</li> <li>Performance: Reduced resource usage and faster CI/CD pipelines.</li> </ol>"},{"location":"package_managers/#common-package-manager-commands","title":"Common Package Manager Commands","text":""},{"location":"package_managers/#uv-commands","title":"uv Commands","text":"<pre><code># Install dependencies from pyproject.toml\nuv pip install -e .\n\n# Install a specific package\nuv pip install package_name\n\n# Install with specific version\nuv pip install package_name==1.0.0\n\n# Install development dependencies\nuv pip install -e \".[dev]\"\n\n# Create a virtual environment\nuv venv\n\n# Update the lock file\nuv pip compile pyproject.toml -o uv.lock\n\n# Install from lock file\nuv pip sync uv.lock\n</code></pre>"},{"location":"package_managers/#equivalent-commands-in-other-package-managers","title":"Equivalent Commands in Other Package Managers","text":"Task uv pip Poetry Conda Install dependencies <code>uv pip install -e .</code> <code>pip install -e .</code> <code>poetry install</code> <code>conda install --file requirements.txt</code> Install package <code>uv pip install pkg</code> <code>pip install pkg</code> <code>poetry add pkg</code> <code>conda install pkg</code> Create environment <code>uv venv</code> <code>python -m venv venv</code> <code>poetry env use python</code> <code>conda create -n env_name</code> Update lock file <code>uv pip compile</code> <code>pip-compile</code> <code>poetry lock</code> <code>conda env export &gt; environment.yml</code> Install from lock <code>uv pip sync uv.lock</code> <code>pip install -r requirements.txt</code> <code>poetry install</code> <code>conda env update -f environment.yml</code>"},{"location":"package_managers/#conclusion","title":"Conclusion","text":"<p>Package managers are crucial tools in modern Python development. While there are several options available, each with its own strengths and weaknesses, our project benefits significantly from using uv due to its performance, reliability, and modern feature set.</p> <p>By using uv, we ensure consistent development environments, faster dependency installation, and a streamlined workflow that enhances productivity across the team.</p>"},{"location":"python_formatters/","title":"Python Code Formatters: A Comprehensive Guide","text":""},{"location":"python_formatters/#introduction","title":"Introduction","text":"<p>Code formatters are essential tools in modern software development that automatically format code according to predefined style rules. They help maintain consistent code style across a project, improve readability, and eliminate debates about formatting preferences. This document provides an overview of popular Python code formatters, with a special focus on Ruff, which is the formatter used in the ForestFire project.</p>"},{"location":"python_formatters/#why-use-code-formatters","title":"Why Use Code Formatters?","text":"<ol> <li>Consistency: Ensures uniform code style across the entire codebase</li> <li>Productivity: Eliminates time spent on manual formatting</li> <li>Readability: Makes code easier to read and understand</li> <li>Collaboration: Reduces conflicts in code reviews about style preferences</li> <li>Focus: Allows developers to focus on logic rather than formatting</li> <li>Onboarding: Makes it easier for new developers to adapt to project standards</li> </ol>"},{"location":"python_formatters/#common-python-formatters","title":"Common Python Formatters","text":""},{"location":"python_formatters/#1-black","title":"1. Black","text":"<p>Black is a popular, opinionated code formatter that aims to provide a consistent style by reformatting entire files in place.</p> <p>Key Features: - \"Uncompromising\" code formatting with minimal configuration options - Deterministic output (same input always produces same output) - Reformats entire files - PEP 8 compliant (with some exceptions) - Widely adopted in the Python community</p> <p>Limitations: - Limited configurability by design - Some developers find its style choices too rigid - Can produce unexpected formatting in certain edge cases</p>"},{"location":"python_formatters/#2-yapf-yet-another-python-formatter","title":"2. YAPF (Yet Another Python Formatter)","text":"<p>YAPF is a formatter from Google that aims to produce code that follows the style guide, even if the original code didn't.</p> <p>Key Features: - Highly configurable - Multiple predefined styles (pep8, Google, etc.) - Reformats code to look as much like hand-formatted code as possible - Can be configured to match personal preferences</p> <p>Limitations: - Can be slower than other formatters - Many configuration options can lead to inconsistency between projects - Less popular than Black or Ruff</p>"},{"location":"python_formatters/#3-autopep8","title":"3. autopep8","text":"<p>autopep8 automatically formats Python code to conform to the PEP 8 style guide.</p> <p>Key Features: - Focuses specifically on PEP 8 compliance - Conservative by default (makes minimal changes) - Configurable aggressiveness level - Can fix specific issues or entire files</p> <p>Limitations: - Less comprehensive than other formatters - Doesn't handle some complex formatting cases - Primarily focused on fixing PEP 8 violations rather than comprehensive formatting</p>"},{"location":"python_formatters/#4-isort","title":"4. isort","text":"<p>isort is a specialized formatter that sorts imports alphabetically and automatically separates them into sections.</p> <p>Key Features: - Specialized in organizing and formatting import statements - Configurable import sections - Can be integrated with other formatters - Supports various styles (Google, PEP8, etc.)</p> <p>Limitations: - Only handles import statements - Must be used alongside other formatters for complete code formatting</p>"},{"location":"python_formatters/#ruff-the-modern-python-formatter-and-linter","title":"Ruff: The Modern Python Formatter and Linter","text":""},{"location":"python_formatters/#overview","title":"Overview","text":"<p>Ruff is a fast, Rust-based Python linter and formatter that aims to replace multiple Python tools (like Black, isort, pycodestyle, flake8, etc.) with a single, high-performance solution. It's designed to be a drop-in replacement for existing tools while offering significant performance improvements.</p>"},{"location":"python_formatters/#key-features-of-ruff","title":"Key Features of Ruff","text":""},{"location":"python_formatters/#1-exceptional-performance","title":"1. Exceptional Performance","text":"<ul> <li>Blazing Fast: Ruff is 10-100x faster than traditional Python linters and formatters</li> <li>Rust Implementation: Built with Rust for memory safety and performance</li> <li>Incremental Formatting: Can efficiently format only changed files</li> </ul>"},{"location":"python_formatters/#2-comprehensive-functionality","title":"2. Comprehensive Functionality","text":"<ul> <li>Formatter and Linter: Combines formatting and linting in a single tool</li> <li>Import Sorting: Includes isort-compatible import sorting</li> <li>Rule Selection: Supports over 700 built-in rules</li> <li>Auto-fixes: Can automatically fix many issues it identifies</li> </ul>"},{"location":"python_formatters/#3-compatibility","title":"3. Compatibility","text":"<ul> <li>Black-Compatible: Can produce Black-compatible output</li> <li>Configuration Compatibility: Supports configuration from pyproject.toml and other standard files</li> <li>IDE Integration: Works with popular IDEs and editors</li> </ul>"},{"location":"python_formatters/#4-configurability","title":"4. Configurability","text":"<ul> <li>Flexible Configuration: Extensive configuration options while maintaining sensible defaults</li> <li>Rule Selection: Enable/disable specific rules or rule categories</li> <li>Line Length: Configurable line length and other formatting options</li> </ul>"},{"location":"python_formatters/#using-ruff-in-the-forestfire-project","title":"Using Ruff in the ForestFire Project","text":"<p>Our project leverages Ruff for code formatting and linting with the following configuration:</p> <ol> <li>Configuration in pyproject.toml:    ```toml    [tool.ruff]    # Set the maximum line length to 80.    line-length = 80</li> </ol> <p>[tool.ruff.lint]    # Add the <code>line-too-long</code> rule to the enforced rule set.    extend-select = [\"E501\"]    ```</p> <ol> <li>Pre-commit Integration:    ```yaml    repos:<ul> <li>repo: https://github.com/astral-sh/ruff-pre-commit    rev: v0.3.0    hooks:<ul> <li>id: ruff</li> <li>id: ruff-format    ```</li> </ul> </li> </ul> </li> </ol>"},{"location":"python_formatters/#benefits-of-using-ruff-in-our-project","title":"Benefits of Using Ruff in Our Project","text":"<ol> <li>Development Speed: Faster formatting and linting means less time waiting and more time coding</li> <li>Consistency: Ensures uniform code style across the entire codebase</li> <li>Modern Tooling: Support for the latest Python features and best practices</li> <li>Simplified Workflow: Single tool for formatting, linting, and import sorting</li> <li>Performance: Reduced resource usage and faster CI/CD pipelines</li> <li>Pre-commit Integration: Automatic formatting and linting before commits</li> </ol>"},{"location":"python_formatters/#common-formatter-commands","title":"Common Formatter Commands","text":""},{"location":"python_formatters/#ruff-commands","title":"Ruff Commands","text":"<pre><code># Format a file\nruff format file.py\n\n# Format all Python files in a directory\nruff format .\n\n# Format and fix linting issues\nruff check --fix file.py\n\n# Check for issues without fixing\nruff check file.py\n\n# Format and check imports\nruff format --select I file.py\n</code></pre>"},{"location":"python_formatters/#equivalent-commands-in-other-formatters","title":"Equivalent Commands in Other Formatters","text":"Task Ruff Black isort autopep8 Format file <code>ruff format file.py</code> <code>black file.py</code> N/A <code>autopep8 file.py</code> Format directory <code>ruff format .</code> <code>black .</code> N/A <code>autopep8 .</code> Sort imports <code>ruff check --select I --fix</code> N/A <code>isort .</code> N/A Check without changing <code>ruff check</code> <code>black --check .</code> <code>isort --check .</code> <code>autopep8 --diff .</code>"},{"location":"python_formatters/#integrating-formatters-with-development-workflow","title":"Integrating Formatters with Development Workflow","text":""},{"location":"python_formatters/#1-editor-integration","title":"1. Editor Integration","text":"<p>Most modern code editors support integration with Python formatters:</p> <ul> <li>VS Code: Extensions for Ruff, Black, and other formatters</li> <li>PyCharm: Built-in support or plugins for formatters</li> <li>Vim/Neovim: Plugins available for formatter integration</li> </ul>"},{"location":"python_formatters/#2-pre-commit-hooks","title":"2. Pre-commit Hooks","text":"<p>Pre-commit hooks ensure code is formatted before being committed:</p> <pre><code># .pre-commit-config.yaml\nrepos:\n  - repo: https://github.com/astral-sh/ruff-pre-commit\n    rev: v0.3.0\n    hooks:\n      - id: ruff\n      - id: ruff-format\n</code></pre>"},{"location":"python_formatters/#3-cicd-integration","title":"3. CI/CD Integration","text":"<p>Add formatting checks to CI/CD pipelines to ensure all code meets the project's style requirements:</p> <pre><code># Example GitHub Actions workflow\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - uses: actions/setup-python@v4\n        with:\n          python-version: '3.12'\n      - name: Install dependencies\n        run: pip install ruff\n      - name: Check formatting\n        run: ruff format --check .\n</code></pre>"},{"location":"python_formatters/#conclusion","title":"Conclusion","text":"<p>Code formatters are crucial tools in modern Python development. While there are several options available, each with its own strengths and weaknesses, our project benefits significantly from using Ruff due to its performance, comprehensive functionality, and modern feature set.</p> <p>By using Ruff, we ensure consistent code style, faster development cycles, and a streamlined workflow that enhances productivity across the team.</p>"},{"location":"python_logging/","title":"Python Logging: A Comprehensive Guide","text":""},{"location":"python_logging/#introduction","title":"Introduction","text":"<p>Logging is a critical aspect of software development that provides insights into application behavior, helps with debugging, and creates an audit trail of application activities. This document provides an overview of Python logging options, with a special focus on Loguru, which is the logging library used in the ForestFire project.</p>"},{"location":"python_logging/#python-logging-options","title":"Python Logging Options","text":""},{"location":"python_logging/#1-standard-library-logging","title":"1. Standard Library Logging","text":"<p>Python's built-in <code>logging</code> module provides a flexible framework for emitting log messages from applications:</p> <p>Key Features: - Part of the standard library - Hierarchical loggers - Multiple output handlers - Configurable formatting - Log levels (DEBUG, INFO, WARNING, ERROR, CRITICAL)</p> <p>Limitations: - Complex configuration - Verbose setup code - Limited formatting options - No built-in support for structured logging</p> <p>Example:</p> <pre><code>import logging\n\n# Configure logger\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n    handlers=[logging.FileHandler(\"app.log\"), logging.StreamHandler()]\n)\n\n# Create logger\nlogger = logging.getLogger(__name__)\n\n# Use logger\nlogger.info(\"Application started\")\nlogger.error(\"An error occurred: %s\", error_message)\n</code></pre>"},{"location":"python_logging/#2-third-party-logging-libraries","title":"2. Third-Party Logging Libraries","text":"<p>Several third-party libraries extend Python's logging capabilities:</p>"},{"location":"python_logging/#a-structlog","title":"a. Structlog","text":"<p>Key Features: - Structured logging - Context binding - Flexible output formats (JSON, key-value) - Integration with standard logging</p>"},{"location":"python_logging/#b-python-json-logger","title":"b. Python-json-logger","text":"<p>Key Features: - JSON-formatted logs - Compatible with standard logging - Simple configuration</p>"},{"location":"python_logging/#c-logbook","title":"c. Logbook","text":"<p>Key Features: - Modern API - Thread-local context - Multiple handlers - Improved performance</p>"},{"location":"python_logging/#loguru-the-modern-python-logger","title":"Loguru: The Modern Python Logger","text":""},{"location":"python_logging/#overview","title":"Overview","text":"<p>Loguru is a library that aims to make logging in Python simpler, more intuitive, and more powerful. It's designed to be a drop-in replacement for the standard logging module with a much more pleasant API.</p>"},{"location":"python_logging/#key-features-of-loguru","title":"Key Features of Loguru","text":""},{"location":"python_logging/#1-simplicity-and-ease-of-use","title":"1. Simplicity and Ease of Use","text":"<ul> <li>No Logger Configuration: No need to create and configure loggers</li> <li>No Handlers Setup: Simplified handler configuration</li> <li>No Formatters: Built-in, customizable formatting</li> <li>No Boilerplate: Ready to use out of the box</li> </ul>"},{"location":"python_logging/#2-advanced-features","title":"2. Advanced Features","text":"<ul> <li>Colored Output: Automatic colorization of terminal output</li> <li>Structured Logging: Support for structured contextual information</li> <li>Exception Capturing: Detailed exception information with traceback</li> <li>Asynchronous, Thread-Safe: Works well in concurrent environments</li> <li>Customizable Levels: Define custom log levels</li> <li>Rotation Features: Built-in log rotation capabilities</li> <li>Notifiers: Email, Telegram, and other notification options</li> </ul>"},{"location":"python_logging/#3-modern-python-support","title":"3. Modern Python Support","text":"<ul> <li>String Formatting: Uses new-style string formatting</li> <li>Type Annotations: Full type hint support</li> <li>Context Variables: Support for contextvars</li> <li>Async Support: Works well with async code</li> </ul>"},{"location":"python_logging/#using-loguru-in-the-forestfire-project","title":"Using Loguru in the ForestFire Project","text":"<p>The ForestFire project leverages Loguru for logging with the following configuration:</p> <pre><code>from loguru import logger\n\n# Configure logger\nlogger.configure(\n    handlers=[\n        {\n            \"sink\": print,\n            \"format\": \"&lt;green&gt;{time:HH:mm:ss}&lt;/green&gt; | \"\n                      \"&lt;level&gt;{level: &lt;8}&lt;/level&gt; | \"\n                      \"&lt;red&gt;{message}&lt;/red&gt;\"\n                      if \"{level}\" == \"ERROR\"\n                      else \"&lt;green&gt;{time:HH:mm:ss}&lt;/green&gt; | \"\n                      \"&lt;level&gt;{level: &lt;8}&lt;/level&gt; | \"\n                      \"&lt;level&gt;{message}&lt;/level&gt;\",\n            \"colorize\": True,\n            \"level\": \"INFO\",\n            \"diagnose\": True,  # Adds traceback for errors\n        }\n    ]\n)\n\n# Use logger with context\nwith logger.contextualize(task_id=\"optimization\"):\n    logger.info(\"Starting optimization with {} pickers\", NUM_PICKERS)\n\n    # Log errors with detailed traceback\n    try:\n        # Code that might raise an exception\n        pass\n    except Exception as e:\n        logger.error(\"Error in optimization process: {}\", e)\n        raise\n</code></pre>"},{"location":"python_logging/#benefits-of-using-loguru-in-forestfire","title":"Benefits of Using Loguru in ForestFire","text":"<ol> <li>Development Speed: Minimal setup and configuration</li> <li>Readability: Clean, colorized logs that are easy to read</li> <li>Contextual Information: Task IDs and other context in logs</li> <li>Error Diagnosis: Detailed exception information</li> <li>Flexibility: Easy to add new log destinations</li> <li>Consistency: Uniform logging across the application</li> </ol>"},{"location":"python_logging/#logging-best-practices","title":"Logging Best Practices","text":""},{"location":"python_logging/#1-log-levels","title":"1. Log Levels","text":"<p>Use appropriate log levels for different types of information:</p> <ul> <li>DEBUG: Detailed information, typically useful only for diagnosing problems</li> <li>INFO: Confirmation that things are working as expected</li> <li>WARNING: Indication that something unexpected happened, but the application is still working</li> <li>ERROR: Due to a more serious problem, the application has not been able to perform a function</li> <li>CRITICAL: A serious error indicating that the application itself may be unable to continue running</li> </ul>"},{"location":"python_logging/#2-contextual-information","title":"2. Contextual Information","text":"<p>Include relevant context in log messages:</p> <pre><code># Good\nlogger.info(\"Processing order {order_id} for customer {customer_id}\", order_id=123, customer_id=456)\n\n# Not as good\nlogger.info(\"Processing order\")\n</code></pre>"},{"location":"python_logging/#3-structured-logging","title":"3. Structured Logging","text":"<p>Use structured logging for machine-readable logs:</p> <pre><code># With Loguru\nlogger.bind(order_id=123, customer_id=456).info(\"Processing order\")\n</code></pre>"},{"location":"python_logging/#4-exception-handling","title":"4. Exception Handling","text":"<p>Log exceptions with full context:</p> <pre><code>try:\n    # Code that might raise an exception\n    process_data()\nexcept Exception as e:\n    logger.exception(\"Error processing data: {}\", e)\n    # or with Loguru\n    logger.error(\"Error processing data: {}\", e)  # Loguru captures traceback automatically\n</code></pre>"},{"location":"python_logging/#5-performance-considerations","title":"5. Performance Considerations","text":"<p>Be mindful of logging performance:</p> <pre><code># Avoid expensive operations in log messages\nif logger.level(\"DEBUG\").enabled:\n    logger.debug(\"Complex calculation result: {}\", expensive_calculation())\n</code></pre>"},{"location":"python_logging/#common-logging-patterns","title":"Common Logging Patterns","text":""},{"location":"python_logging/#1-application-entry-points","title":"1. Application Entry Points","text":"<p>Log application startup and shutdown:</p> <pre><code>logger.info(\"Application starting\")\n# Application code\nlogger.info(\"Application shutting down\")\n</code></pre>"},{"location":"python_logging/#2-function-entry-and-exit","title":"2. Function Entry and Exit","text":"<p>Log function entry and exit for important functions:</p> <pre><code>def process_data(data_id):\n    logger.debug(\"Starting to process data {}\", data_id)\n    # Processing code\n    logger.debug(\"Finished processing data {}\", data_id)\n</code></pre>"},{"location":"python_logging/#3-error-boundaries","title":"3. Error Boundaries","text":"<p>Log at error boundaries:</p> <pre><code>try:\n    # Code that might fail\n    result = api_call()\nexcept Exception as e:\n    logger.error(\"API call failed: {}\", e)\n    raise\n</code></pre>"},{"location":"python_logging/#4-performance-metrics","title":"4. Performance Metrics","text":"<p>Log performance metrics:</p> <pre><code>import time\n\nstart_time = time.time()\n# Code to measure\nelapsed = time.time() - start_time\nlogger.info(\"Operation completed in {:.2f} seconds\", elapsed)\n</code></pre>"},{"location":"python_logging/#json-logging-for-services","title":"JSON Logging for Services","text":"<pre><code>import sys\nimport json\n\ndef json_formatter(record):\n    record_dict = {\n        \"timestamp\": record[\"time\"].strftime(\"%Y-%m-%d %H:%M:%S\"),\n        \"level\": record[\"level\"].name,\n        \"message\": record[\"message\"],\n        \"module\": record[\"name\"],\n    }\n    # Add extra attributes\n    record_dict.update(record[\"extra\"])\n    return json.dumps(record_dict)\n\nlogger.configure(\n    handlers=[\n        {\n            \"sink\": sys.stdout,\n            \"format\": json_formatter,\n            \"level\": \"INFO\",\n        }\n    ]\n)\n</code></pre>"},{"location":"python_logging/#migrating-from-standard-logging-to-loguru","title":"Migrating from Standard Logging to Loguru","text":"<p>If you're considering migrating from the standard logging module to Loguru, here's a simple guide:</p>"},{"location":"python_logging/#standard-logging","title":"Standard Logging:","text":"<pre><code>import logging\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\nlogger.info(\"Processing %s items\", num_items)\nlogger.error(\"Error: %s\", error_message)\n</code></pre>"},{"location":"python_logging/#loguru-equivalent","title":"Loguru Equivalent:","text":"<pre><code>from loguru import logger\n\nlogger.info(\"Processing {} items\", num_items)\nlogger.error(\"Error: {}\", error_message)\n</code></pre>"},{"location":"python_logging/#interoperability-with-existing-code","title":"Interoperability with Existing Code:","text":"<pre><code>from loguru import logger\nimport logging\n\n# Redirect standard logging to loguru\nclass InterceptHandler(logging.Handler):\n    def emit(self, record):\n        # Get corresponding Loguru level if it exists\n        try:\n            level = logger.level(record.levelname).name\n        except ValueError:\n            level = record.levelno\n\n        # Find caller from where originated the logged message\n        frame, depth = logging.currentframe(), 2\n        while frame.f_code.co_filename == logging.__file__:\n            frame = frame.f_back\n            depth += 1\n\n        logger.opt(depth=depth, exception=record.exc_info).log(\n            level, record.getMessage()\n        )\n\nlogging.basicConfig(handlers=[InterceptHandler()], level=0, force=True)\n</code></pre>"},{"location":"python_logging/#conclusion","title":"Conclusion","text":"<p>Logging is a critical component of any production-ready application. Loguru provides a modern, intuitive, and powerful logging solution that simplifies the logging process while offering advanced features.</p> <p>By using Loguru in the ForestFire project, we benefit from simplified setup, colorized output, contextual logging, and detailed error information, all of which contribute to better debugging, monitoring, and maintenance of the application.</p>"}]}